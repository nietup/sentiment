{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza sentymentu\n",
    "Implementacja wzorowana na:\n",
    "https://medium.com/@alyafey22/sentiment-classification-from-keras-to-the-browser-7eda0d87cdc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, RepeatVector, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.models import save_model\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "import csv \n",
    "import pandas as pd \n",
    "from IPython.display import display, HTML\n",
    "import h5py\n",
    "from random import shuffle\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file = 'dane_treningowe.csv'):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        labels = []\n",
    "        text = []\n",
    "\n",
    "        lines = f.readlines()\n",
    "    shuffle(lines)\n",
    "    for line in lines:\n",
    "        data = line.split(',')\n",
    "        if len(data) == 2:\n",
    "            labels.append(data[1])\n",
    "            text.append(data[0].rstrip())\n",
    "    return text,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@abigailjones7 that hurts abigail...i thought we were closer than that  ... douscherrr value:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(sys.argv) == 2:\n",
    "    filename = sys.argv[1]\n",
    "else:\n",
    "    filename = 'dane_treningowe.csv'\n",
    "    \n",
    "x_train_text, y_train = load_dataset(filename)\n",
    "# x_train_text = x_train_text[:5000]\n",
    "# y_train = y_train[:5000]\n",
    "data_text = x_train_text\n",
    "\n",
    "print(x_train_text[30], \"value: \", y_train[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Eliminujemy:\n",
    "* znaki interpunkcyjne (\".\", \"?\", itp), ponieważ nie niosą ze sobą wartości emocjonalnej\n",
    "\n",
    "Zostawiamy:\n",
    "* \"#\", \"@\" ponieważ słowa używane jako twitter handler/hasztag mogą mieć inne znaczenie niż same słowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(txt):\n",
    "    out = txt\n",
    "    out = re.sub(r'[.,\"!?:*_-]', '', txt)\n",
    "    out = re.sub('&quot;', '', txt)\n",
    "    out = out.split()\n",
    "    out = [word.lower() for word in out]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"a\"', 'a!', 'a.', 'a,', 'a?', 'a:a', 'a*', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(process('\"a\" a! a. a, a? a:a a* &quot;a&quot;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(thresh = 2):\n",
    "    count  = dict()\n",
    "    idx = 1\n",
    "    word_index = dict()\n",
    "    for txt in data_text:\n",
    "        words = process(txt)\n",
    "        for word in words:\n",
    "            if word in count.keys():\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word]  = 1\n",
    "    most_counts = [word for word in count.keys() if count[word]>=thresh]\n",
    "    \n",
    "    sorted_words = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    for word in most_counts:\n",
    "        word_index[word] = idx\n",
    "        idx+=1\n",
    "    return word_index, sorted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMax(data):\n",
    "    max_tokens = 0 \n",
    "    for txt in data:\n",
    "        if max_tokens < len(txt.split()):\n",
    "            max_tokens = len(txt.split())\n",
    "    return max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = getMax(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data):\n",
    "    tokens = []\n",
    "    for txt in data:\n",
    "        words = process(txt)\n",
    "        seq = [0] * max_tokens\n",
    "        i = 0 \n",
    "        for word in words:\n",
    "            start = max_tokens-len(words)\n",
    "            if word.lower() in word_index.keys():\n",
    "                seq[i+start] = word_index[word]\n",
    "            i+=1\n",
    "        tokens.append(seq)        \n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dictionary  68\n"
     ]
    }
   ],
   "source": [
    "word_index, sorted_words = tokenize()\n",
    "num_words = len(word_index) + 1\n",
    "print('length of the dictionary ', len(word_index))\n",
    "\n",
    "#print(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = create_sequences(x_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje metryki\n",
    "Funkcje na recall i precision wzięte z implementacji Keras <2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batchwise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multilabel classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batchwise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multilabel classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    f1 = 2*precision*recall/(precision + recall)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiowanie modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 26, 8)             552       \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 26, 8)             544       \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 26, 4)             208       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 26, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 26, 4)             144       \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 2)                 56        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,507\n",
      "Trainable params: 1,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "embedding_size = 8\n",
    "model1.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model1.add(LSTM(units=8,return_sequences=True))\n",
    "model1.add(LSTM(units=4,return_sequences=True))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(LSTM(units=4 ,return_sequences=True))\n",
    "model1.add(LSTM(units=2, ))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 26, 8)             552       \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 26, 16)            1600      \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 26, 8)             800       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 26, 8)             0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 26, 8)             544       \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 3,709\n",
      "Trainable params: 3,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "embedding_size = 8\n",
    "model2.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model2.add(LSTM(units=16,return_sequences=True))\n",
    "model2.add(LSTM(units=8,return_sequences=True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(LSTM(units=8 ,return_sequences=True))\n",
    "model2.add(LSTM(units=4, ))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 26, 8)             552       \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 26, 32)            5248      \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 26, 16)            3136      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 26, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 26, 16)            2112      \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 4)                 336       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 11,389\n",
      "Trainable params: 11,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "embedding_size = 8\n",
    "model3.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model3.add(LSTM(units=32,return_sequences=True))\n",
    "model3.add(LSTM(units=16,return_sequences=True))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(LSTM(units=16 ,return_sequences=True))\n",
    "model3.add(LSTM(units=4, ))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 26, 8)             552       \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 26, 64)            18688     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 26, 32)            12416     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 26, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 26, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 43,129\n",
      "Trainable params: 43,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "embedding_size = 8\n",
    "model4.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model4.add(LSTM(units=64,return_sequences=True))\n",
    "model4.add(LSTM(units=32,return_sequences=True))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(LSTM(units=32 ,return_sequences=True))\n",
    "model4.add(LSTM(units=16, ))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model4.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 26, 8)             552       \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 26, 128)           70144     \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 26, 64)            49408     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 26, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 165,577\n",
      "Trainable params: 165,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "embedding_size = 8\n",
    "model5.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "model5.add(LSTM(units=128,return_sequences=True))\n",
    "model5.add(LSTM(units=64,return_sequences=True))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(LSTM(units=64 ,return_sequences=True))\n",
    "model5.add(LSTM(units=32, ))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model5.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening i weryfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = [int(i) for i in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 12s 246ms/step - loss: 0.7244 - acc: 0.3404 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 0.6687 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.7198 - acc: 0.3404 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 0.6722 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.7155 - acc: 0.3404 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 0.6759 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.7091 - acc: 0.3404 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 0.6797 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.7053 - acc: 0.3404 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: nan - val_loss: 0.6836 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: nan\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train_tokens, y_train_int, validation_split=0.05, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 11s 241ms/step - loss: 0.6728 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7949 - val_loss: 0.7291 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6679 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7867 - val_loss: 0.7371 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6618 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7941 - val_loss: 0.7443 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6575 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7938 - val_loss: 0.7522 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7938 - val_loss: 0.7611 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train_tokens, y_train_int, validation_split=0.05, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 11s 239ms/step - loss: 0.6853 - acc: 0.6809 - precision: 0.6994 - recall: 0.8567 - f1: 0.7700 - val_loss: 0.7134 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6739 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7938 - val_loss: 0.7324 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6638 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7941 - val_loss: 0.7515 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6555 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7949 - val_loss: 0.7705 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7915 - val_loss: 0.7885 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train_tokens, y_train_int, validation_split=0.05, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.6927 - acc: 0.4894 - precision: 0.2340 - recall: 0.3191 - f1: nan - val_loss: 0.7194 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6762 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7867 - val_loss: 0.7508 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6586 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7941 - val_loss: 0.7840 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6426 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7910 - val_loss: 0.8265 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6385 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7910 - val_loss: 0.8839 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x_train_tokens, y_train_int, validation_split=0.05, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      "47/47 [==============================] - 13s 269ms/step - loss: 0.6842 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7941 - val_loss: 0.7617 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.6458 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7938 - val_loss: 0.9062 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.6440 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7949 - val_loss: 0.9704 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.6545 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7867 - val_loss: 0.9325 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.6482 - acc: 0.6596 - precision: 0.6596 - recall: 1.0000 - f1: 0.7938 - val_loss: 0.8452 - val_acc: 0.3333 - val_precision: 0.3333 - val_recall: 1.0000 - val_f1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(x_train_tokens, y_train_int, validation_split=0.05, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy w zależności od liczby neuronów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c8b10d7320>]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c8b6f9b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [history1.history['acc'][4], \n",
    "           history2.history['acc'][4], \n",
    "           history3.history['acc'][4], \n",
    "           history4.history['acc'][4], \n",
    "           history5.history['acc'][4]]\n",
    "\n",
    "neurons = [18, 36, 68, 144, 288]\n",
    "\n",
    "plt.xlabel('liczba neuronow')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(neurons, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
